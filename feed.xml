<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://yongsik-lee.github.io/ai810-gdl/feed.xml" rel="self" type="application/atom+xml"/><link href="https://yongsik-lee.github.io/ai810-gdl/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-06-08T17:08:13+08:00</updated><id>https://yongsik-lee.github.io/ai810-gdl/feed.xml</id><title type="html">AI810_Geometric Deep Learning</title><subtitle>Home to the 2025 ICLR Blogposts track </subtitle><entry><title type="html">sample</title><link href="https://yongsik-lee.github.io/ai810-gdl/blog/distill-example/" rel="alternate" type="text/html" title="sample"/><published>2025-10-28T00:00:00+08:00</published><updated>2025-10-28T00:00:00+08:00</updated><id>https://yongsik-lee.github.io/ai810-gdl/blog/distill-example</id><content type="html" xml:base="https://yongsik-lee.github.io/ai810-gdl/blog/distill-example/"><![CDATA[<p>test 3</p> <p>Note: please use the table of contents as defined in the front matter rather than the traditional markdown styling.</p> <h2 id="equations">Equations</h2> <p>This theme supports rendering beautiful math in inline and display modes using <a href="https://www.mathjax.org/">MathJax 3</a> engine. You just need to surround your math expression with <code class="language-plaintext highlighter-rouge">$$</code>, like <code class="language-plaintext highlighter-rouge">$$ E = mc^2 $$</code>. If you leave it inside a paragraph, it will produce an inline expression, just like \(E = mc^2\).</p> <p>To use display mode, again surround your expression with <code class="language-plaintext highlighter-rouge">$$</code> and place it as a separate paragraph. Here is an example:</p> \[\left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right)\] <p>Note that MathJax 3 is <a href="https://docs.mathjax.org/en/latest/upgrading/whats-new-3.0.html">a major re-write of MathJax</a> that brought a significant improvement to the loading and rendering speed, which is now <a href="http://www.intmath.com/cg5/katex-mathjax-comparison.php">on par with KaTeX</a>.</p> <h2 id="images-and-figures">Images and Figures</h2> <p>Its generally a better idea to avoid linking to images hosted elsewhere - links can break and you might face losing important information in your blog post. To include images in your submission in this way, you must do something like the following:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{% include figure.html path="assets/img/2025-04-28-distill-example/iclr.png" class="img-fluid" %}
</code></pre></div></div> <p>which results in the following image:</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/iclr-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/iclr-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/iclr-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-distill-example/iclr.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>To ensure that there are no namespace conflicts, you must save your asset to your unique directory <code class="language-plaintext highlighter-rouge">/assets/img/2025-04-28-[SUBMISSION NAME]</code> within your submission.</p> <p>Please avoid using the direct markdown method of embedding images; they may not be properly resized. Some more complex ways to load images (note the different styles of the shapes/shadows):</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/9-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/9-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/9-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-distill-example/9.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/7-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-distill-example/7.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A simple, elegant caption looks good between image rows, after each row, or doesn't have to be there at all. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/8-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/8-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/8-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-distill-example/8.jpg" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/10-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/10-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/10-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-distill-example/10.jpg" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/11-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/11-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/11-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-distill-example/11.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/12-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/12-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/12-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-distill-example/12.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-distill-example/7-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-distill-example/7.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h3 id="interactive-figures">Interactive Figures</h3> <p>Here‚Äôs how you could embed interactive figures that have been exported as HTML files. Note that we will be using plotly for this demo, but anything built off of HTML should work (<strong>no extra javascript is allowed!</strong>). All that‚Äôs required is for you to export your figure into HTML format, and make sure that the file exists in the <code class="language-plaintext highlighter-rouge">assets/html/[SUBMISSION NAME]/</code> directory in this repository‚Äôs root directory. To embed it into any page, simply insert the following code anywhere into your page.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{% include [FIGURE_NAME].html %} 
</code></pre></div></div> <p>For example, the following code can be used to generate the figure underneath it.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">plotly.express</span> <span class="k">as</span> <span class="n">px</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv</span><span class="sh">'</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="nf">density_mapbox</span><span class="p">(</span>
    <span class="n">df</span><span class="p">,</span> <span class="n">lat</span><span class="o">=</span><span class="sh">'</span><span class="s">Latitude</span><span class="sh">'</span><span class="p">,</span> <span class="n">lon</span><span class="o">=</span><span class="sh">'</span><span class="s">Longitude</span><span class="sh">'</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="sh">'</span><span class="s">Magnitude</span><span class="sh">'</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">center</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span><span class="n">lat</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lon</span><span class="o">=</span><span class="mi">180</span><span class="p">),</span> <span class="n">zoom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mapbox_style</span><span class="o">=</span><span class="sh">"</span><span class="s">stamen-terrain</span><span class="sh">"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">write_html</span><span class="p">(</span><span class="sh">'</span><span class="s">./assets/html/2025-04-28-distill-example/plotly_demo_1.html</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>And then include it with the following:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"l-page"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;iframe</span> <span class="na">src=</span><span class="s">"{{ 'assets/html/2025-04-28-distill-example/plotly_demo_1.html' | relative_url }}"</span> <span class="na">frameborder=</span><span class="s">'0'</span> <span class="na">scrolling=</span><span class="s">'no'</span> <span class="na">height=</span><span class="s">"600px"</span> <span class="na">width=</span><span class="s">"100%"</span><span class="nt">&gt;&lt;/iframe&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> <p>Voila!</p> <div class="l-page"> <iframe src="/ai810-gdl/assets/html/2025-04-28-distill-example/plotly_demo_1.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <h2 id="citations">Citations</h2> <p>Citations are then used in the article body with the <code class="language-plaintext highlighter-rouge">&lt;d-cite&gt;</code> tag. The key attribute is a reference to the id provided in the bibliography. The key attribute can take multiple ids, separated by commas.</p> <p>The citation is presented inline like this: <d-cite key="gregor2015draw"></d-cite> (a number that displays more information on hover). If you have an appendix, a bibliography is automatically created and populated in it.</p> <p>Distill chose a numerical inline citation style to improve readability of citation dense articles and because many of the benefits of longer citations are obviated by displaying more information on hover. However, we consider it good style to mention author last names if you discuss something at length and it fits into the flow well‚Äâ‚Äî‚Äâthe authors are human and it‚Äôs nice for them to have the community associate them with their work.</p> <hr/> <h2 id="footnotes">Footnotes</h2> <p>Just wrap the text you would like to show up in a footnote in a <code class="language-plaintext highlighter-rouge">&lt;d-footnote&gt;</code> tag. The number of the footnote will be automatically generated.<d-footnote>This will become a hoverable footnote.</d-footnote></p> <hr/> <h2 id="code-blocks">Code Blocks</h2> <p>This theme implements a built-in Jekyll feature, the use of Rouge, for syntax highlighting. It supports more than 100 languages. This example is in C++. All you have to do is wrap your code in a liquid tag:</p> <p>{% highlight c++ linenos %} <br/> code code code <br/> {% endhighlight %}</p> <p>The keyword <code class="language-plaintext highlighter-rouge">linenos</code> triggers display of line numbers. You can try toggling it on or off yourself below:</p> <figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="k">const</span> <span class="err">\</span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
<span class="n">string</span> <span class="n">myString</span><span class="p">;</span>

    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"input a string: "</span><span class="p">;</span>
    <span class="n">getline</span><span class="p">(</span><span class="n">cin</span><span class="p">,</span> <span class="n">myString</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">length</span> <span class="o">=</span> <span class="n">myString</span><span class="p">.</span><span class="n">length</span><span class="p">();</span>

    <span class="kt">char</span> <span class="n">charArray</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">char</span> <span class="o">*</span> <span class="p">[</span><span class="n">length</span><span class="p">];</span>

    <span class="n">charArray</span> <span class="o">=</span> <span class="n">myString</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">length</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">){</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">charArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">" "</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure> <hr/> <h2 id="blockquotes">Blockquotes</h2> <blockquote> We do not grow absolutely, chronologically. We grow sometimes in one dimension, and not in another, unevenly. We grow partially. We are relative. We are mature in one realm, childish in another. ‚ÄîAnais Nin </blockquote> <hr/> <h2 id="layouts">Layouts</h2> <p>The main text column is referred to as the body. It is the assumed layout of any direct descendants of the <code class="language-plaintext highlighter-rouge">d-article</code> element.</p> <div class="fake-img l-body"> <p>.l-body</p> </div> <p>For images you want to display a little larger, try <code class="language-plaintext highlighter-rouge">.l-page</code>:</p> <div class="fake-img l-page"> <p>.l-page</p> </div> <p>All of these have an outset variant if you want to poke out from the body text a little bit. For instance:</p> <div class="fake-img l-body-outset"> <p>.l-body-outset</p> </div> <div class="fake-img l-page-outset"> <p>.l-page-outset</p> </div> <p>Occasionally you‚Äôll want to use the full browser width. For this, use <code class="language-plaintext highlighter-rouge">.l-screen</code>. You can also inset the element a little from the edge of the browser by using the inset variant.</p> <div class="fake-img l-screen"> <p>.l-screen</p> </div> <div class="fake-img l-screen-inset"> <p>.l-screen-inset</p> </div> <p>The final layout is for marginalia, asides, and footnotes. It does not interrupt the normal flow of <code class="language-plaintext highlighter-rouge">.l-body</code>-sized text except on mobile screen sizes.</p> <div class="fake-img l-gutter"> <p>.l-gutter</p> </div> <hr/> <h2 id="other-typography">Other Typography?</h2> <p>Emphasis, aka italics, with <em>asterisks</em> (<code class="language-plaintext highlighter-rouge">*asterisks*</code>) or <em>underscores</em> (<code class="language-plaintext highlighter-rouge">_underscores_</code>).</p> <p>Strong emphasis, aka bold, with <strong>asterisks</strong> or <strong>underscores</strong>.</p> <p>Combined emphasis with <strong>asterisks and <em>underscores</em></strong>.</p> <p>Strikethrough uses two tildes. <del>Scratch this.</del></p> <ol> <li>First ordered list item</li> <li>Another item <ul> <li>Unordered sub-list.</li> </ul> </li> <li>Actual numbers don‚Äôt matter, just that it‚Äôs a number <ol> <li>Ordered sub-list</li> </ol> </li> <li> <p>And another item.</p> <p>You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we‚Äôll use three here to also align the raw Markdown).</p> <p>To have a line break without a paragraph, you will need to use two trailing spaces. Note that this line is separate, but within the same paragraph. (This is contrary to the typical GFM line break behavior, where trailing spaces are not required.)</p> </li> </ol> <ul> <li>Unordered lists can use asterisks</li> <li>Or minuses</li> <li>Or pluses</li> </ul> <p><a href="https://www.google.com">I‚Äôm an inline-style link</a></p> <p><a href="https://www.google.com" title="Google's Homepage">I‚Äôm an inline-style link with title</a></p> <p><a href="https://www.mozilla.org">I‚Äôm a reference-style link</a></p> <p><a href="../blob/master/LICENSE">I‚Äôm a relative reference to a repository file</a></p> <p><a href="http://slashdot.org">You can use numbers for reference-style link definitions</a></p> <p>Or leave it empty and use the <a href="http://www.reddit.com">link text itself</a>.</p> <p>URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or <a href="http://www.example.com">http://www.example.com</a> and sometimes example.com (but not on Github, for example).</p> <p>Some text to show that the reference links can follow later.</p> <p>Here‚Äôs our logo (hover to see the title text):</p> <p>Inline-style: <img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 1"/></p> <p>Reference-style: <img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 2"/></p> <p>Inline <code class="language-plaintext highlighter-rouge">code</code> has <code class="language-plaintext highlighter-rouge">back-ticks around</code> it.</p> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">var</span> <span class="nx">s</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">JavaScript syntax highlighting</span><span class="dl">"</span><span class="p">;</span>
<span class="nf">alert</span><span class="p">(</span><span class="nx">s</span><span class="p">);</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Python syntax highlighting</span><span class="sh">"</span>
<span class="nf">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No language indicated, so no syntax highlighting. 
But let's throw in a &lt;b&gt;tag&lt;/b&gt;.
</code></pre></div></div> <p>Colons can be used to align columns.</p> <table> <thead> <tr> <th>Tables</th> <th style="text-align: center">Are</th> <th style="text-align: right">Cool</th> </tr> </thead> <tbody> <tr> <td>col 3 is</td> <td style="text-align: center">right-aligned</td> <td style="text-align: right">$1600</td> </tr> <tr> <td>col 2 is</td> <td style="text-align: center">centered</td> <td style="text-align: right">$12</td> </tr> <tr> <td>zebra stripes</td> <td style="text-align: center">are neat</td> <td style="text-align: right">$1</td> </tr> </tbody> </table> <p>There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don‚Äôt need to make the raw Markdown line up prettily. You can also use inline Markdown.</p> <table> <thead> <tr> <th>Markdown</th> <th>Less</th> <th>Pretty</th> </tr> </thead> <tbody> <tr> <td><em>Still</em></td> <td><code class="language-plaintext highlighter-rouge">renders</code></td> <td><strong>nicely</strong></td> </tr> <tr> <td>1</td> <td>2</td> <td>3</td> </tr> </tbody> </table> <blockquote> <p>Blockquotes are very handy in email to emulate reply text. This line is part of the same quote.</p> </blockquote> <p>Quote break.</p> <blockquote> <p>This is a very long line that will still be quoted properly when it wraps. Oh boy let‚Äôs keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can <em>put</em> <strong>Markdown</strong> into a blockquote.</p> </blockquote> <p>Here‚Äôs a line for us to start with.</p> <p>This line is separated from the one above by two newlines, so it will be a <em>separate paragraph</em>.</p> <p>This line is also a separate paragraph, but‚Ä¶ This line is only separated by a single newline, so it‚Äôs a separate line in the <em>same paragraph</em>.</p>]]></content><author><name>Albert Einstein</name></author><summary type="html"><![CDATA[sample]]></summary></entry><entry><title type="html">AI810 Blog Post (20205266)</title><link href="https://yongsik-lee.github.io/ai810-gdl/blog/20205266/" rel="alternate" type="text/html" title="AI810 Blog Post (20205266)"/><published>2025-04-28T00:00:00+08:00</published><updated>2025-04-28T00:00:00+08:00</updated><id>https://yongsik-lee.github.io/ai810-gdl/blog/20205266</id><content type="html" xml:base="https://yongsik-lee.github.io/ai810-gdl/blog/20205266/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>This blogpost reviews two recent papers: ‚ÄúRegulatory DNA Sequence Design with Reinforcement Learning‚Äù and ‚ÄúGenerator Matching: Generative Modeling with Arbitrary Markov Processes.‚Äù While they are thematically distinct as the former addresses biological sequence design and the latter focuses on a unified framework of generative modeling, they are adjacent as both tackles the problem of generative processes. The first paper explores how reinforcement learning (RL) can improve the optimization of cis-regulatory DNA sequences, a crucial problem in synthetic biology. The second paper introduces a unifying mathematical framework for generative modeling through the lens of parameterized Markov processes. Furthermore, as an RL researcher, I provide my viewpoint of these papers in RL perspective.</p> <h2 id="regulatory-dna-sequence-design-with-reinforcement-learning-taco-">Regulatory DNA Sequence Design with Reinforcement Learning (TACO) <d-cite key="yang2025regulatory"></d-cite></h2> <blockquote> <p>This paper presents TACO, a generative method that leverages RL to fine-tune a pre-trained autoregressive model and also incorporates biological priors into the reward to design CREs with high fitness and diversity. <br/> <strong>Revivew Outline</strong>: This paper addresses the problem of DNA sequence design, which requires some understanding of biological concepts. As these may be unfamiliar to us, I begin with a brief introduction to them. Then I present the core content of the paper. Finally, I offer my detailed criticism and personal commentary.</p> </blockquote> <h3 id="biological-background">Biological Background</h3> <p>As we come from an AI background, I first provide a brief summary of relevant biological concepts appearing in this paper, based on my own understanding with external sources.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-biology-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-biology-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-biology-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-biology.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Conceptual flow of gene expression control. </div> <ul> <li><strong>DNA</strong>: a sequence of nucleotides (A, T, C, and G) that encodes genetic information. <ul> <li><strong>Gene</strong>: a sub-sequence of DNA. Genes are not always active. <strong>Gene expression</strong> is the process that encodes a gene‚Äôs information into proteins.</li> <li><strong>Cis-regulatory elements (CRE)</strong>: a non-coding sub-sequence of DNA that acts as on/off switch to control gene expression. A <strong>promoter</strong> determines when and where a gene is activated, and an <strong>enhancer</strong> boosts the level of gene expression. The ability of a CRE to modulate gene expression is referred to as its <strong>fitness</strong>. <ul> <li><strong>Transcription Factor Binding Sites (TFBS)</strong>: a short sequence motif within a CRE.</li> </ul> </li> </ul> </li> <li><strong>Transcription Factor (TF)</strong>: a protein that recognizes and binds to a specific TFBS. This binding influences a CRE‚Äôs regulation of gene expression. An <strong>activator</strong> TF promotes gene transcription and expression, while a <strong>repressor</strong> TF hinders them.</li> </ul> <p>In summary, a TF binding to a CRE via its TFBS modulates gene expression and each gene is regulated by distinct TFs and CREs.</p> <h3 id="overview">Overview</h3> <h4 id="-motivation">üìå Motivation</h4> <p>CREs play an essential role in regulating gene expression in a cell-type-specific manner. While millions of putative CREs have been identified over the past decade, most are naturally evolved and cover only a small region of the possible sequence space. Therefore, the design of synthetic CREs with <em>desired fitness</em> is a promising direction, with broad applications across diverse domains.</p> <p>The design of high-fitness CREs has primarily relied on <em>directed evolution</em>, which iteratively mutates and selects sequences in wet-lab settings. More recently, <em>fitness prediction models</em> have been utilized as reward models to guide CRE optimization. However, current methods suffer from two limiations:</p> <ul> <li>Although the sequence space is large, they rely on local modifcation of existing or random sequences with iterative optimization, resulting in <em>local optima</em> and <em>low diversity</em>.</li> <li>They generally do not utilize <em>biological prior knowledge</em>.</li> </ul> <h4 id="-key-contributions">üìå Key Contributions</h4> <p>This paper proposes <strong>TACO</strong> (<strong>T</strong>FBS-<strong>A</strong>ware <strong>C</strong>is-regulatory element <strong>O</strong>ptimization), a RL fine-tuning method for a pre-trained autoregressive (AR) DNA model incorporating biological priors of TFBS information to improve CRE optimization. The key contributions are:</p> <ul> <li><strong>RL Fine-tuning for Pre-trained AR DNA Generative Models</strong>: The suggested paradigm enables the generation of sequences with significantly higher diversity while also exploring those with superior functional performance.</li> <li><strong>Biologically-informed Prior Guided TFBS Reward</strong>: The authors discover that using only TFBS frequency features of a CRE sequence can achieve high performance on CRE fitness prediction tasks. Moreover, the potential contribution of each TFBS is inferred via SHAP value and implemented as additional rewards.</li> <li><strong>Generation of high fitness and diversity Cell-type specific CREs</strong>: TACO is evaluated under different optimization settings (active learning and offline model-based optimization) on real-world datasets and demostrated its effectiveness.</li> </ul> <h3 id="method">Method</h3> <h4 id="-problem-formulation">üìå Problem Formulation</h4> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-method-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-method-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-method-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-method.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Overview of TACO, illustrating AR generation of a DNA sequence (BOS represents the beginning of the sequence). </div> <p>A DNA sequence \(X = ( x_1, \cdots, x_L )\) is defined as a sequence of nUcleotides, where \(x_i \in \{A, C, G, T \}\) represents the nucleotide at the \(i\)-th position. The sequence has length \(L\). A large-scale dataset of CRE sequences with fitness measurements, \(D = \{ (X_1, f (X_1)), \cdots, (X_N, f (X_N)) \}\), is available. \(D_\text{low}\) is a subset of low-fitness sequences. In RL framework, the sequence generation is formulated as a <em>Markov Decision Process (MDP)</em>:</p> <ul> <li><strong>State</strong>: \(s_i\), a partially generated DNA sequences up to time step \(i\)</li> <li><strong>Action</strong>: \(a_i \in \{A, C, G, T \}\), the next nucleotide at position \(i\)</li> <li><strong>Policy</strong>: \(\pi_\theta\), the AR generative model</li> <li><strong>Reward</strong>: \(r(s_{i-1}, a_i) = \begin{cases} r_{\text{fitness}}, &amp; \text{if } i = L \\ r_{\text{TFBS}}(t), &amp; \text{if } a_i \text{ results in a TFBS } t \in T \\ 0, &amp; \text{otherwise} \end{cases}\)</li> </ul> <p>The generation process is illustrated in the above figure. The process terminates when the sequence length reaches $L$ and \(r_{\text{fitness}}\) is given by the reward model. Whenever a TFBS \(T = \{t_1, t_2, \cdots, t_n\}\) is identified, a positive (or negative) reward \(r_{\text{TFBS}}(t)\) is given for generating activating (or repressive) TFBS.</p> <h4 id="-step-1-pre-training-cre-specific-ar-model">üìå Step 1: Pre-training CRE-specific AR Model</h4> <p>In the pre-training stage, HyenaDNA <d-cite key="nguyen2023hyenadna"></d-cite> is adapted for the AR model by continual training on \(D_{\text{low}}\). As HyenaDNA is trained on the entire human genome, continual pre-training is performed for CRE-specific regulatory patterns. Furthermore, pre-training on \(D_{\text{low}}\) helps the policy generate sequences that resemble the true CRE distribution <d-cite key="jin2020multi"></d-cite><d-cite key="chen2021molecule"></d-cite>, offering a good starting point for RL fine-tuning. The objective is to minimize:</p> \[\min_{\theta} \mathbb{E}_{x \sim D_{\text{low}}} \left[ \sum_{i=1}^{L} -\log \pi_{\theta}(a_i \mid a_1, \cdots, a_{i-1}) \right]\] <h4 id="-step-2-rl-fine-tuning-for-ar-dna-models">üìå Step 2: RL Fine-tuning for AR DNA Models</h4> <p>With the aforementioned MDP formulation, the objective in RL fine-tuning stage is to maximize the expected cumulative rewards:</p> \[\max_{\theta} J(\theta) = \mathbb{E}_{\pi_\theta} \left[ \sum_{i=1}^{L} r(s_{i-1}, a_i) \right]\] <p>REINFORCE <d-cite key="williams1992simple"></d-cite> is used to train the policy, and a hill climbing replay buffer and entropy regularization are utilized as auxiliary techniques following prior works <d-cite key="blaschke2020reinvent"></d-cite><d-cite key="ghugaresearching"></d-cite> to balance exploration and exploitation, thus improving performance.</p> <h4 id="-inference-of-tfbs-regulatory-roles-integrating-biological-prior">üìå Inference of TFBS Regulatory Roles (Integrating Biological Prior)</h4> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-method2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-method2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-method2-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-method2.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Inference of TFBS Reward $r_{\text{TFBS}}(t)$ </div> <p>Firstly, construct the feature vector \(h(X) = [h_1(X), h_2(X), \cdots, h_n(X)]\) where \(h_j(X)\) denotes the frequency of the TFBS \(t_j\) in sequence \(X\). LightGBM <d-cite key="ke2017lightgbm"></d-cite>, a decision-tree model, is trained to predict CRE fitness with this feature.</p> <p>Then the contribution of each TFBS frequency feature \(h_j(X)\) to the fitness prediction of the LightGBM model is inferred using SHAP values <d-cite key="lundberg2017unified"></d-cite> <d-footnote>SHAP values are a theoretically grounded method to estimate the contribution of each feature to the prediction of a model.</d-footnote>. The SHAP value \(\phi_j(X)\) for \(j\)-th TFBS \(t_j\) in sequence \(X\) is:</p> \[\phi_j(X) = \sum_{S \subseteq \{1, \dots, n\} \setminus \{j\}} \frac{|S|!(n - |S| - 1)!}{n!} \left( \hat{f}(S \cup \{j\}) - \hat{f}(S) \right)\] <p>where \(S\) is a subset of features not containing \(j\) and \(\hat{f}\) is the model prediction. Then the TFBS reward \(r_{\text{TFBS}}(t)\) is computed as:</p> \[r_{\text{TFBS}}(t) = \begin{cases} \alpha \cdot \mu_\phi(t), &amp; \text{if } p\text{-value} &lt; 0.05 \\ 0, &amp; \text{otherwise} \end{cases}\] <p>where \(\alpha\) is a hyperparameter and \(\mu_\phi(t)\) is the mean SHAP value of TFBS \(t\) across the dataset. <d-footnote> By assigning rewards only when p-value is less than 0.05, only statistically significant TFBSs contribute to the reawrds. </d-footnote> These rewards are incorporated into the RL fine-tuning to encourage activator TFBSs and discourage repressive TFBSs.</p> <h3 id="results--analysis">Results &amp; Analysis</h3> <h4 id="-experimental-setup">üìå Experimental Setup</h4> <p>The experiments are conducted on two datasets: <strong>yeast promoter</strong>, which includes two types of growth media (<em>complex</em> and <em>defined</em>) with DNA sequence length 80, and <strong>human enhancer</strong>, which consists of three cell lines (<em>HepG2</em>, <em>K562</em>, and <em>SK-N-SH</em>) with sequence length 200. MPRAs <d-cite key="sharon2012inferring"></d-cite> were employed to obtain all paired CRE sequences and their corresponding fitness measurements.</p> <p>Three evaluation metrics are used. <em>Top</em> is the mean fitness of highest-performaing 16 sequences from the optimized set \(\mathcal{X}^* = \{X_1, \ldots, X_K\}\) of 256 sequences. <d-footnote> In each optimization round, $K=256$ sequences are generated. </d-footnote> Both <em>Medium</em> and <em>Diversity</em> are computed using the highest-performing 128 sequences from the set of 256 sequences. <em>Medium</em> is the median fitness among 128 sequences, and <em>Diversity</em> is the median pairwise distance between all pairs within 128 sequences.</p> <p>For baselines, FLEXS <d-cite key="sinai2020adalead"></d-cite> <d-footnote> FLEXS is a benchmark introduced in AdaLead paper. The FLEXS baseline in this paper corresponds to the Bayesian optimization implementation from that benchmark. </d-footnote>, AdaLead <d-cite key="sinai2020adalead"></d-cite>, PEX <d-cite key="anand2022protein"></d-cite> and CMAES <d-cite key="auger2012tutorial"></d-cite> are based on traditional optimization methods. DNARL is the modified version of the SOTA protein optimization method <d-cite key="lee2024robust"></d-cite> for CRE optimization.</p> <h4 id="-setting-1-active-learning">üìå Setting 1: Active Learning</h4> <p>The oracle trained on the entire dataset \(D\) is available in this setting, and employed as a reward model. <d-footnote> The oracle is employed for RL fine-tuning (as a reward model) and for evaluation. </d-footnote> Easy, middle, and hard subsets are constructed for each datset according to fitness values. These subsets are used as \(D_{\text{low}}\) to pre-train the AR model for each difficulty.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-exp1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-exp1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-exp1-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-exp1.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Results on human enhancer dataset in activate learning setting </div> <p>The above table shows the results on human enhancer dataset for final optimized set \(\mathcal{X}^*\) after 100 optimization rounds. TACO achieves both high fitness and diversity compared to the baselines. Similar results are obtained on yeast promoters dataset for each difficulty. <d-footnote> The results on yeast promoters dataset are omitted for clarity. </d-footnote></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-exp2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-exp2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-exp2-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-exp2.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Evaluation metrics after each optimization round on human enhancer dataset </div> <p>This figure shows the evaluation metrics after each optimization round. Among all methods, only TACO achieves both a stable increase in fitness and high diversity. Compared to other baselines, TACO‚Äôs generative modeling paradigm enables this performance.</p> <h4 id="-setting-2-offline-model-based-optimization-mbo">üìå Setting 2: Offline Model-based Optimization (MBO)</h4> <p>In the previous active learning setting, we assumed the accessiblity to the oracle but what if we it is not available? In this offline MBO <d-cite key="reddy2024designing"></d-cite> <d-footnote> From the reference paper, the goal of an offline MBO algorithm is to produce designs which maximize an objective using a static dataset. The proxy objective function (surrogate in this paper) is trained, and the algorithms optimizes this proxy. The produced design is evaluated by the true objective. </d-footnote> setting , the AR model is pre-trained on the complete dataset \(D\) to simulate real-world scenarios in which sequences are rich but their fitness lables are unavailable. The <em>surrogate</em> fitness prediction model is trained on \(D_{\text{offline}}\), the smaller subset of \(D\), and used during RL fine-tuning. The new metric <em>Emb Similarity</em> is introduced to quantify the diversity of the final proposed sequences. <d-footnote> Emb Similarity is computed as the average pairwise cosine similarity of the embeddings of the proposed sequences. Here, the embeddings are obtained from the oracle. This metric can estimate the diversity of sequences in the latent feature space. </d-footnote></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-exp3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-exp3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-exp3-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-exp3.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Results on human enhancer dataset (K562) in offline MBO setting </div> <p>This table shows the results on K562 dataset. Two conditional generative models, regLM and DDSM are included as additional baselines. Due to unavailability of the oracle, the overall performance of each method decreases compared to the active learning setting. Again, TACO achieves both high fitness and diversity. Other methods are imbalanced between fitness and diversity, or are inferior to TACO.</p> <h4 id="-ablation-study">üìå Ablation Study</h4> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-exp4-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-exp4-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-exp4-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-20205266/TACO-exp4.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Results of the ablation study. </div> <p>The above table demostrates the results of the abltaion study under offline MBO setting for two major components: pre-training and TFBS reward. For pre-training, ‚Äòw/o pretraining‚Äô (which uses a random initialization of the policy) achieves better performance for a particular metric in some cases, but are inferior for Medium metric. This indicates that pre-training helps the policy to start from a relatively reasonable exploration space. For TFBS reward, employing TFBS reward improves the Medium metric, indicating the prior-informed rewards facilitate efficient exploration of the policy in a more rational sequence space. When \(\alpha\) increases from 0.01 to 0.1, overall performance degrades on HepG2, and Top and Medium metrics improves but Diversity worsens on K562 and SK-N-SH. This discrepancy would be due to the varying quality of TFBS reward across datasets.</p> <h3 id="personal-analysis-and-commentary">Personal Analysis and Commentary</h3> <p>In <em>Strengths</em> and <em>Weaknesses, Limitations and Critique</em>, I present comments and evaluations on the paper in general viewpoint. In <em>Opinion as an RL Researcher</em>, I share my thoughts from the viewpoint of a RL researcher. <em>Thoughts on Future Research</em> proposes several potential directions for future work inspired by this paper. Lastly, I present what I personally gained from this paper in <em>Personal Takeaways</em>.</p> <h4 id="-strengths">üìå Strengths</h4> <ul> <li><strong>Novelty of TFBS Reward</strong>: TACO incorporates TFBS motif information as biological prior knowledge into TFBS rewards, and is one of the first method leveraging such information in machine learning-based CRE design. Furthermore, the suggested TFBS reward is surrogate-agnostic.</li> <li><strong>Novelty of RL-based CRE design</strong>: Unlike prior optimization-based methods, the authors introduced RL with pre-training AR for CRE, which provides a new paradigm in this domain.</li> <li><strong>Comprehensive Design of the Method</strong>: The overall design of method is comprehensive, and each component is modularied and well-integrated.</li> <li><strong>Empirical Validation</strong>: The authors validated the effectiveness of TACO across different settings and datasets, where TACO achieves both high fitness and diversity compared to baselines.</li> </ul> <h4 id="-weaknesses-limitations-and-critique">üìå Weaknesses, Limitations and Critique</h4> <ul> <li><strong>Presentation and Clarity</strong>: There are several typos throughout the paper. And I found few parts are unclear to understand. The writing would be would be improved.</li> <li><strong>Missing Analysis on Emb Similarity</strong>: While the authors introduced <em>Emb Similarity</em> as an additional metric in offline MBO experiment, they do not provide explanation or justification on this metric. The Emb Similarity is very high compared to baselines, and this tendency is observed across datasets and difficulties as shown in the tables in appendix of the paper. This raises doubts whether TACO truly generate diverse sequences.</li> <li><strong>Limitation of TFBS Reward</strong>: While the integration of biological priors as TFBS reward is novel, TFBS reward is only based on TFBS frequency and SHAP values. This simple structure does not consider other factors such as interactions between TFs and their orientation which can impact their regulatory roles <d-cite key="georgakopoulos2023transcription"></d-cite>. Moreover, the current method relied on a fixed TFBS databse, which may set an upper limit of the TFBS reward.</li> <li><strong>Necessity of RL Pipeline</strong>: The overall pipeline is quite complex as it includes diverse factors such as AR pre-training, RL fine-tuning, and TFBS rewards with SHAP values. Morevover, auxiliary techniques, such as hill climing replay buffers, are employed. While TACO demonstrated its effectiveness, it is questionable whether the benefits of using this pipeline justify its complexity. Other baselines seems to be easier to implement and to utilize.</li> <li><strong>No Analysis on Computational Cost</strong>: Related to the previous point, there is no analysis on computational cost. This would help to better understand TACO or to justify its use.</li> <li><strong>Dependency on Learned Reward Model</strong>: As all rewards are obtained from learned reward models, the performance is hightly sensitive to the quality of these reward models.</li> </ul> <h4 id="-opinion-as-an-rl-researcher">üìå Opinion as an RL Researcher</h4> <ul> <li>The authors say that TACO is an RL method for CRE design. Let us revisit this.<br/> While TACO is not a complete offline RL method, it lacks the typical <em>environment</em> in RL and interactions with the environment. In RL, an environment consists of its dynamics (a state transition function) and reward function. However, in TACO, there is no dynamics and policy itself just expands the sequence, i.e., the transition is deterministic. Only rewards are obtained from the separately trained reward models. Thus, we can view TACO as an RL-inspired optimization method.</li> <li>TACO overlaps with various areas of RL, while not perfectly aligned with any one of them. <ul> <li>Model-based RL: Utilize learned reward models, but no dynamics.</li> <li>Offline RL: Pre-train the policy with offline data, but also employ external reward models.</li> <li>On-Policy and Off-Policy RL: TACO uses REINFORCE, an on-policy algorithm, while also employing a replay buffer is off-policy RL.</li> </ul> </li> <li>The construction of TFBS reawrd is a case of <em>reward shaping</em>. Reward shaping provides a way to reflect the domain knowledge and to improve training. However, such shaping is difficult in general. If one wants to integrate further domain knowledge in the current TFBS reward, this process would not be trivial. Furthermore, the shaped reward can results in overfitting, which requires careful consideration.</li> <li>The authors noted that they employ REINFORCE as an RL fine-tuning algorithm following the previous work in molecule optimization. However, there are other advanced options like PPO. While REINFORCE is relatively simple and shows effectiveness with additional auxiliary techniques, using REINFORCE lacks justification.</li> <li>Nevertheless, this work is encouraing as RL techniques demonstrated the potential in real-world applications beyond typical RL simulation benchmarks.</li> </ul> <h4 id="-thoughts-on-future-work">üìå Thoughts on Future Work</h4> <ul> <li>Further development of TFBS reward would be interesting. As noted in the paper, exploring data-driven motif mining or explicitly incorporating factors such as interactions between TFs to model more complex TF activities could be promising directions.</li> <li>One can extend the pipeline of TACO to other protein design tasks and validate its generalization ability. Or, one can extend TACO to multi-objective (in addition to fitness) optimization.</li> <li>Validation in wet-lab setting over simulation-based evaluation would be important. But this is beyond the scope of AI researchers.</li> <li>RL techniques could be futher adjusted or newly adopted for TACO. For example, we can use PPO for RL fine-tuning or apply additional exploration strategies.</li> <li>We can take a hierarchical RL at the motif level. Or, we can introduce a curriculum RL approach.</li> </ul> <h4 id="-personal-takeaways">üìå Personal Takeaways</h4> <p>TACO demonstrated the potential of RL as a promising tool in biology domain. Considering the growing interest in RL as a way to overcome limitations of traditional optimization algorithms, I believe cross-disciplinary collaboration with experts in other domains will become more important. It was also interesting that generative models can be framed in RL perspective. Combining diverse ingredients of RL to build effective and practical generative models is a direction I might explore in future work.</p> <h2 id="generator-matching-generative-modeling-with-arbitrary-markov-processes-">Generator Matching: Generative Modeling with Arbitrary Markov Processes <d-cite key="holderrieth2025generator"></d-cite></h2> <blockquote> <p>This paper presents Generator Matching, a modality-agnostic framework for generative modeling using arbitrary Markov processes. This framework unifies current generative models such as diffusion models, flow matching.<br/> <strong>Revivew Outline</strong>: This paper follows a sequential structure, where each concept and section builds upon the previous one. This review follows the original flow, with partial reorganization for clarity. Part 1 introduces a view of generative modeling as a Markov process. Part 2 presents the core concepts necessary to construct the Generator Matching framework. Part 3 illustrates the Generator Matching and its extensions. A unified view of generative models and experimental results follow. Finally, I present my detailed criticism and commentary.<br/> <strong>Note</strong>: This work is mathematically dense. I focus on the core ideas and equations. Please refer to the paper for full mathematical details.</p> </blockquote> <h3 id="overview-1">Overview</h3> <h4 id="-motivation-1">üìå Motivation</h4> <p>Over the past decade, various generative models such as Diffusion models <d-cite key="ho2020denoising"></d-cite> and Flow models <d-cite key="lipman2022flow"></d-cite> have emerged. Despite their differences, many of these generative models share a common property: starting from easy-to-sample distribution, they iteratively contruct the sample \(X_{t+h}\) of the next time step depeding only on the current state \(X_t\), i.e., they are <strong>Markov processes</strong>.</p> <p>Then, can we design a unified framework for these generative modeling methods?</p> <h4 id="-key-contribution">üìå Key Contribution</h4> <ul> <li><strong>Unified Framework for Generative Modeling</strong>: This paper proposes <strong>Generator Matching (GM)</strong>, a framework for generative modeling with Markov processes on arbitrary state spaces. GM unifies prior generative modeling methods into a common framework that is modality-agnostic.</li> <li><strong>Model Combination</strong>: GM facilitate combining models in two ways. Markov superpositions can construct ensembles of generative models. Multimodal generative models can be constructed by combining GM models built for single data modalities.</li> <li><strong>Universal Characterization and Novel Models</strong>: This paper universally characterize the space of Markovian generative models on discrete and Euclidiean spaces. Moreover, jump models are introduces as an unexplored model class for \(\mathbb{R}^d\).</li> <li><strong>Experiment</strong>: On image and multimodal protein generation tasks, jump models and Markov superpositions achieve competitive results.</li> </ul> <h4 id="-quick-glance-at-gm-framework">üìå Quick Glance at GM framework</h4> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/GM-overview-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/GM-overview-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/GM-overview-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-20205266/GM-overview.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Generator Matching (GM) framework. </div> <p>The above figure illustrates the GM framework to construct generative models. In GM framework, for the chosen state spaces and Markov processes, we find the conditional generator \(L_t^z\) of the Markov process satisfying Kolmogorov Forward Equation (KFE). Then we train \(L_t^\theta\) using the loss based on Bregman divergence. In this way, we can generate samples that approximate marginal data distribution.</p> <h3 id="part-1-generative-modeling">Part 1: Generative Modeling</h3> <h4 id="-probability-path-approach">üìå Probability Path Approach</h4> <p>The goal of generative models is to generate novel samples \(z \sim p_{\text{data}}\) when given samples \(x_1, \ldots, x_N \sim p_{\text{data}}\) from a data distribution \(p_{\text{data}}\) on a state space \(S\). This can be done by transforming a simple distribution \(p_{\text{simple}}\) into \(p_{\text{data}}\) via probability paths. First sample \(z \sim p_{\text{data}}\) and sample \(x \sim p_t(dx\vert z)\) from <strong>conditional probability path</strong>, a set of time-varying probability distributions \((p_t(dx\vert z))_{0 \leq t \leq 1}\). Then we can construct <strong>marginal probability path</strong> which interpolates between \(p_{\text{simple}}\) and \(p_{\text{data}}\):</p> \[z \sim p_{\text{data}}, \quad x \sim p_t(dx|z) \Rightarrow x \sim p_t(dx)\] <p>Now, the first design principle of GM follows:</p> <blockquote> <p><strong>Principle 1</strong><br/> Given a data distribution \(p_{\text{data}}\), choose \(p_{\text{simple}}\) and a conditional probability path such that the marginal path \((p_t)_{0 \leq t \leq 1}\) fulfills \(p_0 = p_{_\text{simple}}\) and \(p_1 = p_{\text{data}}\).</p> </blockquote> <h4 id="-as-a-markov-process">üìå As a Markov Process</h4> <p>We can view generative models as <strong>Markov Processes</strong> <d-cite key="ethier2009markov"></d-cite>. What are Markov Processes? They satisfy the Markov property: the next state depends only on the current state. Mathematically, a time-continuous Markov process is \((X_t)_{0 \leq t \leq 1}\) for \(t \in [0, 1]\) and a random variable \(X_t \in S\), satisfying</p> \[P[X_{t_{n+1}} \in A \mid X_{t_1}, X_{t_2}, \ldots, X_{t_n}] = P[X_{t_{n+1}} \in A \mid X_{t_n}]\] <p>for all \(0 \leq t_1 &lt; t_2 &lt; \cdots &lt; t_n &lt; t_{n+1} \leq 1\) and measurable set \(A \subseteq S\). For each Markov Process, a corresponding <strong>transition kernel</strong> \((k_{t+h \mid t})_{0 \leq t &lt; t+h \leq 1}\) assigns \(x \in S\) a probability distribution \(P[X_{t+h} \in A \mid X_t = x] = k_{t+h \mid t}(A \mid x)\).</p> <p>With a Markov Process, we can generate data samples from \(p_{\text{data}}\) following a marginal probability path \((p_t(dx))_{0 \leq t \leq 1}\): sample \(X_0 \sim p_0\) and simulate \(X_{t+h} \sim k_{t+h \mid t}(\cdot \mid X_t)\) step-wise up to \(t = 1\). However, an abitrary general kernel \(k_{t+h \mid t}\) is difficult to parameterize in a neural network. In diffusion models, the kernel can be closely approximated by simple parametric distributions such as Gaussians for small \(h&gt;0\) <d-cite key="sohl2015deep"></d-cite><d-cite key="ho2020denoising"></d-cite> . This idea can be extended to Markov processes, leading to the <em>generator</em>.</p> <h3 id="part-2-generator">Part 2: Generator</h3> <h4 id="-concept-of-generator">üìå Concept of Generator</h4> <p>Now, what is a generator? For \(k_{t+h \mid t}\) with small \(h&gt;0\), below is an informal version of 1st-order Taylor approximation in \(t\) with an error term \(o(h)\).</p> \[k_{t+h|t} = k_{t|t} + h L_t + o(h), \quad L_t := \left. \frac{d}{dh} \right|_{h=0} k_{t+h|t}, \quad k_{t|t}(\cdot|x) = \delta_x\] <p>The first-order <em>linear</em> approximation \(L_t\) is called <strong>generator</strong> of the kernel \(k_{t+h \mid t}\) <d-cite key="ethier2009markov"></d-cite><d-cite key="ruschendorf2016comparison"></d-cite>. The generator is the core concept of GM, and it will be shown that generative models (such as Diffusion) can be viewed as learning the generator of a Markov process.</p> <p>The problem here is that a probability measure is not a standard function, thus the above equation is not well-defined. Hence, <em>test functions</em> \(f : S \to \mathbb{R}\) are employed to probe probability distributions and to define generator. The actions of marignal \(p_t\) and kernel \(k_{t+h \mid t}\) are defined for all \(f \in \mathcal{T}\) with the linear function:</p> \[\begin{aligned} \langle p_t, f \rangle &amp;\overset{\text{def}}{=} \int f(x)\, p_t(dx) = \mathbb{E}_{x \sim p_t}[f(x)] \quad \text{(Marginal Action)} \\ \langle k_{t+h\mid t}, f \rangle(x) &amp;\overset{\text{def}}{=} \langle k_{t+h\mid t}(\cdot\mid x), f \rangle = \mathbb{E}[f(X_{t+h}) \mid X_t = x] \quad \text{(Transition Action)} \end{aligned}\] <p>Now we can define the generator with these actions.</p> <h4 id="-definition-of-generator">üìå Definition of Generator</h4> <p>Consider the earlier <em>informal</em> Taylor approximation. With test functions and the actions, we can take derivatives of \(\langle k_{t+h \mid t}, f \rangle(x)\) per \(x \in S\):</p> \[\left. \frac{d}{dh} \right|_{h=0} \langle k_{t+h|t}, f \rangle(x) = \lim_{h \to 0} \frac{\langle k_{t+h|t}, f \rangle(x) - f(x)}{h} \overset{\text{def}}{=} [L_t f](x)\] <p>This action is defined as the <strong>generator</strong> \(L_t\). Moreover, the informal Taylor approximation is now well-defined as \(\langle k_{t+h \mid t}, f \rangle = f + h L_t f + o(h)\).</p> <p>Under mild regularity assumptions, there is a unique correspondence between the Markov process and the generator <d-cite key="ethier2009markov"></d-cite><d-cite key="pazy2012semigroups"></d-cite>. Thus, we can parameterize a Markov process via a parameterized generator \(L_t^\theta\). However, directly parameterizing a linear operator \(L_t\) on function spaces with a neural network is difficult. Hence, restrict ourselves to certain subclasses of Markov processes <d-footnote> Flow matching restricts itself to generators $ L_t f = \nabla f(x)^\top u^\theta_t(x) $. </d-footnote>, and parameterize it linearly via a neural network. The following theorem characterizes generators.</p> <blockquote> <p><strong>Theorem 1 (Universal characterization of generators)</strong><br/> Under regularity assumptions <d-footnote> Refer Appendix A.2 in the paper. </d-footnote>, the generators of a Markov processes \(X_t\ (0 \leq t \leq 1)\) take the form:</p> <ol> <li><strong>Discrete</strong> \((|S| &lt; \infty)\): The generator is given by a rate transition matrix \(Q_t\) and the Markov process corresponds to a continuous-time Markov chain (CTMC).</li> <li><strong>Euclidean space</strong> \((S = \mathbb{R}^d)\): The generator has a representation as a sum<br/> \(L_t f(x) = \underbrace{\nabla f(x)^\top u_t(x)}_{\text{flow}} + \underbrace{\frac{1}{2} \nabla^2 f(x) \cdot \sigma_t^2(x)}_{\text{diffusion}} + \underbrace{\int [f(y) - f(x)] Q_t(dy; x)}_{\text{jump}}\) where \(u: [0,1] \times \mathbb{R}^d \rightarrow \mathbb{R}^d\) is a <strong>velocity field</strong>, \(\sigma: [0,1] \times \mathbb{R}^d \rightarrow S^{++}_d\) is the <strong>diffusion coefficient</strong> (\(S^{++}_d =\) positive semi-definite matrices), and \(Q_t(A\mid x)\) is a finite measure called <strong>jump measure</strong>. \(\nabla^2 f(x)\) denotes the Hessian of \(f\) and \(\nabla^2 f(x) \cdot \sigma_t^2(x)\) describes the Frobenius inner product.</li> </ol> </blockquote> <p>Theorem 1 characterizes a wide class of Markov process models as well as the design space <em>exhaustively</em> for \(S = \mathbb{R}^d\) or \(S\) discrete. Now we have the second principle:</p> <blockquote> <p><strong>Principle 2</strong><br/> Parameterize a Markov process via a parameterized generator \(L_t^\theta\). For \(S = \mathbb{R}^d\), pameterize a Markov process (e.g., using a neural network) via a generator \(L_t\) that is composed of (a subset of) velocity \(u_t\), diffusion coefficient \(\sigma_t^ 2\), and jump measure \(Q_t\).</p> </blockquote> <h4 id="-kolmogorov-forward-equation-and-marginal-generator">üìå Kolmogorov Forward Equation and Marginal Generator</h4> <p>The generator can not only parameterize a Markov Process, but also can check if a Markov process generates a desired probability path \(p_t\). The latter is possible via <strong>Kolmogorov Forward Equation (KFE)</strong></p> \[\partial_t \langle p_t, f \rangle = \langle p_t, L_t f \rangle\] <p>which is derived as \(\partial_t \langle p_t, f \rangle = \left.\frac{d}{dh} \right|_{h=0} \langle p_{t+h}, f \rangle = \langle p_t, L_t f \rangle\) <d-footnote> $\langle p_t, \cdot \rangle$ operation is linear to swap the derivative, and the $\langle p_t, \langle k_{t+h|t}, f \rangle \rangle = \langle p_{t+h}, f \rangle$.</d-footnote> . KFE means, for a generator \(L_t\) of a Markov process \(X_t\), we are possible to reconstruct its marginal probabilities via their infinitesimal changes. Conversely, if a generator \(L_t\) of a Markov process \(X_t\) satisfies KFE, \(X_t\) generates the probability path \((p_t)_{0 \leq t \leq 1}\) <d-cite key="rogers2000diffusions"></d-cite>.</p> <p>Now, the key challenge of GM is <strong><em>Given a marginal probability path \((p_t)_{0 \leq t \leq 1}\), find a generator satisfying the KFE</em></strong>. However, the marginal path and a generator for the marginal path (<strong>marginal generator</strong>) are generally unknown or intractable. Let us assume we found a generator \(L_t^z\) the generates \(p_t(\cdot \mid z)\) for every \(z \in S\). This \(L_t^z\) is called <strong>conditional generator</strong>, and we construct marginal generator with \(L_t^z\), i.e., generates a marginal path \(p_t\) with conditional path \(p_t(\cdot \mid z)\).</p> <blockquote> <p><strong>Proposition 1</strong><br/> The marginal probability path \((p_t)_{0 \leq t \leq 1}\) is generated by a Markov process \(X_t\) with generator</p> \[L_t f(x) = \mathbb{E}_{z \sim p_{1|t}(\cdot|x)} [L_t^z f(x)]\] <p>where \(p_{1 \mid t}(dz \mid x)\) is the posterior distribution (i.e., the conditional distribution over data \(z\) given an observation \(x\)). For \(S = \mathbb{R}^d\) and the representation in eq. <strong>Theorem 1</strong>, we get a marginal representation of \(L_t f(x)\) given by:</p> \[\begin{aligned} &amp; \nabla f(x)^\top \mathbb{E}_{z \sim p_{1|t}(\cdot|x)} [u_t(x|z)] + \frac{1}{2} \nabla^2 f(x) \cdot \mathbb{E}_{z \sim p_{1|t}(\cdot|x)} [\sigma_t^2(x|z)] \\ &amp; + \int [f(y) - f(x)] \mathbb{E}_{z \sim p_{1|t}(\cdot|x)} [Q_t(dy;x|z)] \end{aligned}\] <p>Generally, the above identity holds for any linear parameterization of the generator. <d-footnote> Refer Appendix A.6 in the paper. </d-footnote></p> </blockquote> <p>Following Proposition 1, we have the third principle:</p> <blockquote> <p><strong>Principle 3</strong> <br/> Derive a conditional generator \(L_t^z\) satisfying the KFE for the conditional path \(p_t(\cdot|z)\).</p> </blockquote> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/GM-path-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/GM-path-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/GM-path-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-20205266/GM-path.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Markov models trained with different KFE solutions for the same probability path. </div> <p>An important fact is that multiple Markov processes can follow the same probability path, satisfying the same KFE. The above figure illustrate different Markov models for the same probability path.<d-footnote> Refer to Example 1 and 2 in the paper. </d-footnote> For each probability path (Mixture or Geometric Average), each sample path is different. However, the histogram, i.e., the marginal paths are almost the same (MS denotes <em>markov superposition</em> which will be explained in Extension 1 in Part 3).</p> <h3 id="part-3-generator-matching">Part 3: Generator Matching</h3> <h4 id="-generator-matching-method">üìå Generator Matching Method</h4> <p>The final step is to approximate the <em>true</em> marginal generator \(L_t\) with a parameterized generator \(L_t^\theta\). The \(L_t^\theta\) is linearly parameterized by a neural network $F_t^\theta : S \times [0, 1] \rightarrow \Omega$ <d-footnote> $\Omega \subset V$ is a convex subset of some vector space $V$ with inner product $\langle \cdot, \cdot \rangle$.</d-footnote>in practice, and we train \(F_t^\theta\) to approximate the ground-truth parameterization \(F_t : S \times [0, 1] \rightarrow \Omega\) of \(L_t\) (for instance, \(F_t = u_t\) for flows).</p> <p><strong>Bregman divergence</strong> defined with a convex function \(\phi : \Omega \rightarrow \mathbb{R}\), which is a general class of loss functions such as MSE or KL-divergence, is employed as a distance function to measure the discrepancy between \(F_t\) and \(F_t^\theta\):</p> \[D(a, b) = \phi(a) - [\phi(b) + \langle a - b, \nabla \phi(b) \rangle], \quad a, b \in \Omega\] <p>Then we can define <strong>Generator Matching loss</strong>:</p> \[\mathcal{L}_{\text{gm}}(\theta) \overset{\text{def}}{=} \mathbb{E}_{t \sim \text{Unif},\ x \sim p_t} \left[ D(F_t(x), F_t^\theta(x)) \right]\] <p>However, this objective is intractable because the marginal generator \(L_t\) is unknown as mentioned earlier, and \(F_t\) is unknown as well.</p> <p>Note that we know \(F_t^z, F_t^\theta, p_t(\cdot \mid z), D\) and can sample \(z \sim p_{\text{data}}\). Thus, for tractable and scalable training, define <strong>conditional Generator Matching loss</strong>:</p> \[\mathcal{L}_{\text{cgm}}(\theta) \overset{\text{def}}{=} \mathbb{E}_{t \sim \text{Unif},\ z \sim p_{\text{data}},\ x \sim p_t(\cdot | z)} \left[ D(F_t^z(x), F_t^\theta(x)) \right]\] <p>We can assume \(F_t(x) = \int F_t^z(x)\, p_{1\mid t}(dz \mid x)\) from Proposition 1. Then the next proposition shows we can use CGM loss to optimize GM loss.</p> <blockquote> <p><strong>Proposition 2</strong><br/> For any Bregman divergence, the GM loss and CGM loss have the same gradients as the CGM loss \(\mathcal{L}_{\text{cgm}}\), i.e., \(\nabla_\theta \mathcal{L}_{\text{gm}}(\theta) = \nabla_\theta \mathcal{L}_{\text{cgm}}(\theta)\). Therefore, minimizing the CGM loss with Stochastic Gradient Descent will also minimizes the GM loss. Further, for this property to hold, \(D\) must necessarily be a Bregman divergence.</p> </blockquote> <p>Now we can learn \(L_t\) with a scalable objective and <em>universally characterize the space of loss functions</em>. The last principle of GM follows:</p> <blockquote> <p><strong>Principle 4</strong><br/> Train \(L_t^\theta\) by minimizing the CGM loss with a Bregman divergence.</p> </blockquote> <h4 id="-extension-1-combining-models">üìå Extension 1: Combining Models</h4> <p>As the generator is a linear operator and the KFE is a linear equation, we can combine generative models for the same state space.</p> <blockquote> <p><strong>Proposition 3 (Combining models)</strong><br/> Let \(p_t\) be a marginal probability path. Then the following generators solve the KFE for \(p_t\) and consequently define a generative model with \(p_t\) as marginal:</p> <ol> <li><strong>Markov superposition:</strong> \(\alpha_t^1 L_t + \alpha_t^2 L_t'\), where \(L_t, L_t'\) are two generators of Markov processes solving the KFE for \(p_t\), and \(\alpha_t^1, \alpha_t^2 \geq 0\) satisfy \(\alpha_t^1 + \alpha_t^2 = 1\). We call this a <strong>Markov superposition</strong>.</li> <li> <p><strong>Divergence-free components:</strong> \(L_t + \beta_t L_t^{\text{div}}\), where \(L_t^{\text{div}}\) is a generator such that \(\langle p_t, L_t^{\text{div}} f \rangle = 0\) for all \(f \in \mathcal{T}\), and \(\beta_t \geq 0\). We call such \(L_t^{\text{div}}\) <strong>divergence-free</strong>.</p> </li> <li><strong>Predictor-corrector:</strong> \(\alpha_t^1 L_t + \alpha_t^2 \bar{L}_t\), where \(L_t\) is a generator solving the KFE for \(p_t\) in forward-time and \(\bar{L}_t\) is a generator solving the KFE in backward time, and \(\alpha_t^1, \alpha_t^2 \geq 0\) with \(\alpha_t^1 - \alpha_t^2 = 1\).</li> </ol> </blockquote> <h4 id="-extension-2-multimodal-and-high-dimensional-generative-modeling">üìå Extension 2: Multimodal and High-Dimensional Generative Modeling</h4> <p>Furthermore, we can combine generative models from two state spaces \(S_1\), \(S_2\) into the product space \(S_1 \times S_2\). This provides two advantages: we can easily design a joint multimodal generative model easily, and can often reduce solving the KFE in high dimensions to the 1-dimensional case.</p> <blockquote> <p><strong>Proposition 4 (Multimodal generative models ‚Äì Informal version) <d-footnote> Refer to Appendix C.5 in the paper for the rigorous version. </d-footnote></strong><br/> Let \(q_t^1(\cdot | z_1)\), \(q_t^2(\cdot | z_2)\) be two conditional probability paths on state spaces \(S_1\), \(S_2\).<br/> Define the conditional factorized path on \(S_1 \times S_2\) as \(p_t(\cdot | z_1, z_2) = q_t^1(\cdot | z_1)\ q_t^2(\cdot | z_2)\). Let \(p_t(dx)\) be its marginal path.</p> <ol> <li><strong>Conditional generator:</strong><br/> To find a solution to the KFE for the conditional factorized path, we only have to find solutions to the KFE for each \(S_1, S_2\). We can combine them component-wise.</li> <li><strong>Marginal generator:</strong> The marginal generator of \(p_t(dx)\) can be parameterized as follows: (1) parameterize a generator on each \(S_i\) but make it values depend on all dimensions; (2) During sampling, update each component independently as one would do for each \(S_i\) in the unimodal case.</li> <li><strong>Loss function:</strong> We can simply take the sum of loss functions for each \(S_i\).</li> </ol> </blockquote> <p>For example, consider a joint image-text generation with a joint flow and discrete Markov model with \(S_1 = \mathbb{R}^d\), \(S_2 = \{1, \dots, N\}\). A multimodal model can be constructed by making the vector field \(u_t(x_t^1, x_t^2) \in \mathbb{R}^d\) depending on both modalities \(x_t^1\) and \(x_t^2\), but updating the image modality as \(X_{t+h}^1 = X_t^1 + h u_t(X_t^1, X_t^2)\). The text modality is similarly updated depending on both \((X_t^1, X_t^2)\).</p> <h3 id="unified-view">Unified View</h3> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/GM-unified-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/GM-unified-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/GM-unified-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-20205266/GM-unified.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Generative models in GM framework. </div> <p>Now in the GM framework, we can vew genertaive models as methods to learn the generator of a Markov process. The above table shows the examples of important classes of markov processes (note that zero drift is assumed for diffusion). The core components such as generator, KFE, or CGM loss are listed for each Markov process. GM framework provided an unified view of various generative models.</p> <h3 id="experiment">Experiment</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/GM-exp1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/GM-exp1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/GM-exp1-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-20205266/GM-exp1.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/GM-exp2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/GM-exp2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/ai810-gdl/assets/img/2025-04-28-20205266/GM-exp2-1400.webp"/> <img src="/ai810-gdl/assets/img/2025-04-28-20205266/GM-exp2.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Experimental Results. The left table corresponds to aspects 1 and 2, while the right table corresponds to aspect 3. </div> <p>As the design space of the GM framework is large and single classes of models (such as diffusion and flows) have already been optimized in prior works, the experiments focues on three aspects of GM.</p> <h4 id="-aspect-1-jump-models-as-a-novel-model-class">üìå Aspect 1. Jump Models as a novel model class</h4> <p>The left table shows FID scores of image generation for CIFAR10 and ImagetNet32. <d-footnote> Since jump models do not have an equivalent of classifier-free guidance yet, the experiment focus on unconditional generation. </d-footnote> Euler and 2nd order denote Euler sampling and ODE sampler, respectively. While the jump model underperforms compared to the current SOTA models, it shows promising results as a first version of an unexplored class of models.</p> <h4 id="-aspect-2-combining-different-model-classes-markov-superposition">üìå Aspect 2. Combining different model classes (Markov superposition)</h4> <p>Firstly, train a flow and jump model in the same architecture, and validate that the flow part adhives the SOTA performance as before. Then combine both models using a Markov superposition (MS in the left table denotes Markov superposition). Markov superposition significantly improves the performance for Euler sampling. Furthermore, combining 2nd order samplers for flow with Euler sampling for jumps in a <em>mixed</em> sampling outperforms the SOTA flow models. This may futher enhanced by improving the jump model.</p> <h4 id="-aspect-3-multimodal-state-spaces">üìå Aspect 3. Multimodal State Spaces</h4> <p>Next, evaluate the GM‚Äôs ability to design models for arbitrary and complex state spaces with protein generation tasks. Derive \(L_t^z\) to the KFE on \(S=SO(3)\) with a jump model. Then use Proposition 4 to make it multi-dimensional and combine it with a flow model on \(\mathbb{R}^d\) and a discrete Markov model on \(\{1, \ldots, n\}^d\) for \(n=20\) (# amino acids). The state space becomes \(\mathbb{R}^d \times SO(3)^d \times \{1, \ldots, n\}^d\). Without re-training or fine-tuning the pre-trained MultiFlow <d-cite key="campbell2024generative"></d-cite>, the SOTA model, <em>pseudo-marginalize</em> the conditional jumps by predicting \(x \in SE(3)\) and then taking a conditional setp with \(L_t^z\). The right table shows the results, where the metrics Div and Nov represent diversity and novelty, respectively. Both sequence and structure spaces are sampled jointly in multimodal setting, while only the structure is sampled in unimodal setting. Including a jump model achieves SOTA results without re-training or fine-tuning MultiFlow.</p> <h3 id="personal-analysis-and-commentary-1">Personal Analysis and Commentary</h3> <p>As before, I present comments and evaluations on the paper from general viewpoint in <em>Strengths</em> and <em>Weaknesses, Limitations and Critique</em>. In <em>Opinion as an RL Researcher</em>, I provide my thoughts in perspective of a RL researcher. Then I propose potential directions for future work inspired by this paper in <em>Thoughts on Future Research</em>. Finally, I present what I personally gained from this paper in <em>Personal Takeaways</em>.</p> <h4 id="-strengths-1">üìå Strengths</h4> <p>I present the strengths of this paper including key contributions mentioned earlier:</p> <ul> <li> <p><strong>A Unified Generative Modeling Framework</strong>: GM is a unified framework of generative modeling via the concept of generator with Markov processes. This GM frameowrk is modality-agnostic and encompasses various existing generative models such as Diffusion models. While there have been pr works for unifying generative models, I believe this unified framework offers a comprehensive view for people working on generative models.</p> </li> <li> <p><strong>Theretical Foundation</strong>: This work provides comprehensive and rigorous theoretical foundation, grounded in probabilistic process theory. The authors offers solid mathematical details, derivations, and proofs throughout the paper.</p> </li> <li> <p><strong>Recipes to Combine Models</strong>: Using GM framework, we can combine different Markov processes and further extned to multimodal models. These recipes are useful and provide a way to construct diverse generative classes of Markov processes.</p> </li> <li> <p><strong>Novel Models</strong>: This paper introduced a jump model based on jump processes. It takes a novel approach rather than prior flow or diffusion-based methods. While the authors does not highlight, I think the <em>pure diffusion</em> model proposed in this paper is also novel and intersting.</p> </li> <li> <p><strong>Experimental Validation</strong>: The authors validated the effectiveness of GM through several experiments. This can be addressed more comprehensively, but I think it is enough to support GM as the main contribution of this paper is theoretically-grounded unified framework.</p> </li> </ul> <h4 id="-weaknesses-limitations-and-critique-1">üìå Weaknesses, Limitations and Critique</h4> <p>While I believe this work is remarkable and provides strong contributions, I present some critique here.</p> <ul> <li>While I acknowledge the overall experimental setup and scope is enough as the main contribution is theoretically grounded framework, some experimental results are questionable. While the authors state the jump model shows promising results in the image generation task, it significantly underperforms baselines.</li> <li>Related to the previous point, the jump model need more improvements. For example, sampling methods of jump models are less optimized. Moreover, its effectivenss and stability should be validated further.</li> <li>Practical aspects, sucha as the computational cost of learning and utilizing generators, need to be addressed.</li> </ul> <h4 id="-opinion-as-an-rl-researcher-1">üìå Opinion as an RL Researcher</h4> <ul> <li> <p>A fundamental framework of RL is <em>Markov Decision Process</em>, which is also based on Markov property. GM unifies generative modeling via Markov Process. In RL perspective, this can be viewed as action-marginalized dynamics (transitions).</p> </li> <li>Recently, generative models such as diffusion models are utilized as a planner like model-based RL <d-cite key="janner2022planning"></d-cite>. As shown in GM paper, the diffusion model is an example of GM. And we can combine differnt Markov processes in GM framework. When I became aware of this, I came up with the following idea: <ul> <li>Combine multiple diffsion-based planners to construct a multimodal planner</li> <li>Or, combine planners with different or complementary inductive biases This could be a very intersting research direction.</li> </ul> </li> <li>The Bregman divergence was also intersting. As it generalizes many losses inclduing MSE and KL divergence, I think it can be also employed for RL training objectives.</li> </ul> <h4 id="-thoughts-on-future-work-1">üìå Thoughts on Future Work</h4> <ul> <li>Investigating the pure diffusion models introduced in this paper, which learns a diffusion coefficient, would be an interseting direction.</li> <li>Further study of jump models on Euclidiean space could lead to a large class of generative models.</li> <li>We can dive into devlopment of better samplers for jump models.</li> <li>Exploring how GM framework and generators can be employed as a planner for RL would be a promising direction.</li> <li>As GM and jump models are evaluated in two domains, empirical investigation in other domains would be also intersting.</li> </ul> <h4 id="-personal-takeaways-1">üìå Personal Takeaways</h4> <p>I‚Äôm not an expert in generative models. During reading this paper, I gained a comprehensive overview of recent generative models such as diffusion and flow models. The shared Markovian view between generative models and RL was also intersting. Furthermore, I got a promising research idea of combining models to construct RL planners.</p> <h2 id="conclusion">Conclusion</h2> <p>In this blogpost, I reviewed two papers on generative models. The first paper TACO leverages RL for CRE design, and the second paper provides a unified framework via generator of Markov processes for generative modeling. After addressing the key points of each paper, I presented an interpretation as an RL researcher.</p>]]></content><author><name>Yongsik Lee</name></author><summary type="html"><![CDATA[In this blogpost, I review two recent papers related to generative modeling in a viewpoint of a RL researcher.]]></summary></entry></feed>